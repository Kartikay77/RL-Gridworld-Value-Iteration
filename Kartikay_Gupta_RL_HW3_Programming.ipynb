{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fnGkzC4c5p",
        "outputId": "ad77b104-5ab1-44b3-e039-ca3ec1cf2bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "\n",
            "No of iterations: 25 \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Value Function: \n",
            "\n",
            "4.0187   4.5548   5.1575   5.8336   6.4553   \n",
            "\n",
            "4.3716   5.0324   5.8013   6.6473   7.3907   \n",
            "\n",
            "3.8672   4.3900   0.0000   7.5769   8.4637   \n",
            "\n",
            "3.4182   3.8319   0.0000   8.5738   9.6946   \n",
            "\n",
            "2.9977   2.9309   6.0733   9.6946   0.0000   \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Optimal Policy: \n",
            "\n",
            "→   →   →   ↓   ↓   \n",
            "\n",
            "→   →   →   ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑   →   →   G   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Answer 1\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision = 4)\n",
        "gridRows, gridCols = 5, 5\n",
        "gamma = 0.9\n",
        "delta = 0.0001\n",
        "\n",
        "# Value Function\n",
        "v = np.zeros((gridRows, gridCols))\n",
        "\n",
        "# Rewards\n",
        "r = np.array([[0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, -10, 0, 10]])\n",
        "\n",
        "\n",
        "# State 1\n",
        "s0 = (0, 0)\n",
        "\n",
        "# Enviornment Dynamics: A Stochastic MDP\n",
        "water_state = (4, 2)\n",
        "goal_states = [(4, 4)]\n",
        "obstacle_states = [(2, 2), (3, 2)]\n",
        "actions = ['U', 'D', 'L', 'R']\n",
        "print_actions = [u\"\\u2191\", u\"\\u2193\", u\"\\u2190\", u\"\\u2192\"]\n",
        "\n",
        "\n",
        "# Transition function\n",
        "def p(state, action):\n",
        "  next_states = []\n",
        "  next_state_prob = []\n",
        "  rewards = []\n",
        "\n",
        "  state_row, state_col = state[0], state[1]\n",
        "\n",
        "  if action == 'U':\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'D':\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "\n",
        "  if action == 'R':\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'L':\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  return next_states, next_state_prob, rewards\n",
        "\n",
        "# Value Iteration Algorithm\n",
        "iteration_counter = 0\n",
        "\n",
        "while True:\n",
        "  max_diff = 0\n",
        "  v_updated = np.zeros((gridRows, gridCols))\n",
        "  optimal_policy = np.zeros((gridRows, gridCols))\n",
        "\n",
        "  for i in range(gridRows):\n",
        "    for j in range(gridCols):\n",
        "\n",
        "      s = (i, j)\n",
        "      v_s = v[i][j]\n",
        "\n",
        "      if s in goal_states:\n",
        "        v_updated[i][j] = 0\n",
        "      elif s in obstacle_states:\n",
        "        v_updated[i][j] = 0\n",
        "      else:\n",
        "        temp = []\n",
        "        for a in actions:\n",
        "          nextStates, next_state_prob, rewards = p(s, a)\n",
        "          val_update = 0\n",
        "          for n in range(len(nextStates)):\n",
        "            nextState = nextStates[n]\n",
        "            val_update += next_state_prob[n] * (rewards[n] + gamma * v[nextState[0]][nextState[1]])\n",
        "          temp.append(val_update)\n",
        "        v_updated[i][j] = max(temp)\n",
        "        optimal_policy[i][j] = temp.index(max(temp))\n",
        "#         print(v_updated)\n",
        "      max_diff = max(max_diff, abs(v_updated[i][j] - v_s))\n",
        "\n",
        "  iteration_counter += 1\n",
        "  v = v_updated\n",
        "  if max_diff < delta:\n",
        "    break\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nNo of iterations: {} \\n\" .format(iteration_counter))\n",
        "print('*' * 50)\n",
        "print(\"\\nValue Function: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "    print(\"%.4f\" %v[i][j], \"  \", end='')\n",
        "  print(\"\\n\")\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nOptimal Policy: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "\n",
        "    if (i, j) in goal_states:\n",
        "      optimalAction = 'G'\n",
        "    elif (i, j) in obstacle_states:\n",
        "      optimalAction = ' '\n",
        "    else:\n",
        "      optimalAction = print_actions[int(optimal_policy[i][j])]\n",
        "\n",
        "    print(optimalAction, \"  \", end='')\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0tZqoBc4c5q",
        "outputId": "6ab12dd6-5a82-40ff-cc21-a02f88ea0cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "\n",
            "No of iterations: 9 \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Value Function: \n",
            "\n",
            "0.0002   0.0009   0.0042   0.0191   0.0755   \n",
            "\n",
            "0.0008   0.0038   0.0183   0.0879   0.3621   \n",
            "\n",
            "0.0002   0.0008   0.0000   0.4050   1.7373   \n",
            "\n",
            "0.0000   0.0002   0.0000   1.8403   8.3356   \n",
            "\n",
            "0.0000   0.0000   -0.3504   8.3356   0.0000   \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Optimal Policy: \n",
            "\n",
            "→   →   →   ↓   ↓   \n",
            "\n",
            "→   →   →   ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ←   →   →   G   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Answer 2\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision = 4)\n",
        "gridRows, gridCols = 5, 5\n",
        "gamma = 0.25\n",
        "delta = 0.0001\n",
        "\n",
        "# Value Function\n",
        "v = np.zeros((gridRows, gridCols))\n",
        "\n",
        "# Rewards\n",
        "r = np.array([[0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, -10, 0, 10]])\n",
        "\n",
        "\n",
        "# State 1\n",
        "s0 = (0, 0)\n",
        "\n",
        "# Enviornment Dynamics: A Stochastic MDP\n",
        "water_state = (4, 2)\n",
        "goal_states = [(4, 4)]\n",
        "obstacle_states = [(2, 2), (3, 2)]\n",
        "actions = ['U', 'D', 'L', 'R']\n",
        "print_actions = [u\"\\u2191\", u\"\\u2193\", u\"\\u2190\", u\"\\u2192\"]\n",
        "\n",
        "\n",
        "# Transition function\n",
        "def p(state, action):\n",
        "  next_states = []\n",
        "  next_state_prob = []\n",
        "  rewards = []\n",
        "\n",
        "  state_row, state_col = state[0], state[1]\n",
        "\n",
        "  if action == 'U':\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'D':\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "\n",
        "  if action == 'R':\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'L':\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  return next_states, next_state_prob, rewards\n",
        "\n",
        "# Value Iteration Algorithm\n",
        "iteration_counter = 0\n",
        "\n",
        "while True:\n",
        "  max_diff = 0\n",
        "  v_updated = np.zeros((gridRows, gridCols))\n",
        "  optimal_policy = np.zeros((gridRows, gridCols))\n",
        "\n",
        "  for i in range(gridRows):\n",
        "    for j in range(gridCols):\n",
        "\n",
        "      s = (i, j)\n",
        "      v_s = v[i][j]\n",
        "\n",
        "      if s in goal_states:\n",
        "        v_updated[i][j] = 0\n",
        "      elif s in obstacle_states:\n",
        "        v_updated[i][j] = 0\n",
        "      else:\n",
        "        temp = []\n",
        "        for a in actions:\n",
        "          nextStates, next_state_prob, rewards = p(s, a)\n",
        "          val_update = 0\n",
        "          for n in range(len(nextStates)):\n",
        "            nextState = nextStates[n]\n",
        "            val_update += next_state_prob[n] * (rewards[n] + gamma * v[nextState[0]][nextState[1]])\n",
        "          temp.append(val_update)\n",
        "        v_updated[i][j] = max(temp)\n",
        "        optimal_policy[i][j] = temp.index(max(temp))\n",
        "\n",
        "      max_diff = max(max_diff, abs(v_updated[i][j] - v_s))\n",
        "\n",
        "  iteration_counter += 1\n",
        "  v = v_updated\n",
        "  if max_diff < delta:\n",
        "    break\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nNo of iterations: {} \\n\" .format(iteration_counter))\n",
        "print('*' * 50)\n",
        "print(\"\\nValue Function: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "    print(\"%.4f\" %v[i][j], \"  \", end='')\n",
        "  print(\"\\n\")\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nOptimal Policy: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "\n",
        "    if (i, j) in goal_states:\n",
        "      optimalAction = 'G'\n",
        "    elif (i, j) in obstacle_states:\n",
        "      optimalAction = ' '\n",
        "    else:\n",
        "      optimalAction = print_actions[int(optimal_policy[i][j])]\n",
        "\n",
        "    print(optimalAction, \"  \", end='')\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6mvDn184c5r",
        "outputId": "0b787378-8e41-4a70-e133-8c0591ed2e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "\n",
            "No of iterations: 103 \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Value Function: \n",
            "\n",
            "37.9195   43.4592   44.2697   43.4592   37.9195   \n",
            "\n",
            "33.5505   38.1805   43.1982   38.1805   33.5505   \n",
            "\n",
            "29.6599   33.3232   0.0000   33.3232   29.6599   \n",
            "\n",
            "26.2018   29.1002   0.0000   29.1002   26.2018   \n",
            "\n",
            "23.0873   24.5624   19.1278   23.9701   0.0000   \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Optimal Policy: \n",
            "\n",
            "→   →   ↑   ←   ←   \n",
            "\n",
            "→   ↑   ↑   ↑   ←   \n",
            "\n",
            "↑   ↑       ↑   ↑   \n",
            "\n",
            "↑   ↑       ↑   ↑   \n",
            "\n",
            "↑   ↑   ←   ↑   G   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Answer 3\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision = 4)\n",
        "gridRows, gridCols = 5, 5\n",
        "gamma = 0.9\n",
        "delta = 0.0001\n",
        "\n",
        "# Value Function\n",
        "v = np.zeros((gridRows, gridCols))\n",
        "\n",
        "# Rewards\n",
        "r = np.array([[0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, -10, 0, 10]])\n",
        "\n",
        "\n",
        "# State 1\n",
        "s0 = (0, 0)\n",
        "\n",
        "# Enviornment Dynamics: A Stochastic MDP\n",
        "water_state = (4, 2)\n",
        "goal_states = [(4, 4)]\n",
        "obstacle_states = [(2, 2), (3, 2)]\n",
        "actions = ['U', 'D', 'L', 'R']\n",
        "print_actions = [u\"\\u2191\", u\"\\u2193\", u\"\\u2190\", u\"\\u2192\"]\n",
        "\n",
        "r[0][2] = 5\n",
        "\n",
        "\n",
        "# Transition function\n",
        "def p(state, action):\n",
        "    next_states = []\n",
        "    next_state_prob = []\n",
        "    rewards = []\n",
        "\n",
        "    state_row, state_col = state[0], state[1]\n",
        "    if action == 'U':\n",
        "        if state_row == 0:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row - 1, state_col)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.8)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_col == gridCols - 1:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row, state_col + 1)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_col == 0:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row, state_col - 1)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        nextState = state\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.1)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if action == 'D':\n",
        "        if state_row == gridRows - 1:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row + 1, state_col)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.8)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_col == 0:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row, state_col - 1)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_col == gridCols - 1:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row, state_col + 1)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        nextState = state\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.1)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if action == 'R':\n",
        "        if state_col == gridCols - 1:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row , state_col + 1)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.8)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_row == gridRows - 1:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row + 1, state_col)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_row == 0:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row - 1, state_col)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        nextState = state\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.1)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if action == 'L':\n",
        "        if state_col == 0:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row , state_col - 1)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.8)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_row == 0:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row - 1, state_col)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        if state_row == gridRows - 1:\n",
        "            nextState = state\n",
        "        else:\n",
        "            nextState = (state_row + 1, state_col)\n",
        "\n",
        "        if nextState in obstacle_states: # Obstacle\n",
        "            nextState = state\n",
        "\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.05)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "        nextState = state\n",
        "        next_states.append(nextState)\n",
        "        next_state_prob.append(0.1)\n",
        "        rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    return next_states, next_state_prob, rewards\n",
        "\n",
        "# Value Iteration Algorithm\n",
        "iteration_counter = 0\n",
        "\n",
        "while True:\n",
        "    max_diff = 0\n",
        "    v_updated = np.zeros((gridRows, gridCols))\n",
        "    optimal_policy = np.zeros((gridRows, gridCols))\n",
        "    for i in range(gridRows):\n",
        "        for j in range(gridCols):\n",
        "            s = (i, j)\n",
        "            v_s = v[i][j]\n",
        "            if s in goal_states:\n",
        "                v_updated[i][j] = 0\n",
        "            elif s in obstacle_states:\n",
        "                v_updated[i][j] = 0\n",
        "            else:\n",
        "                temp = []\n",
        "                for a in actions:\n",
        "                    nextStates, next_state_prob, rewards = p(s, a)\n",
        "                    val_update = 0\n",
        "                    for n in range(len(nextStates)):\n",
        "                        nextState = nextStates[n]\n",
        "                        val_update += next_state_prob[n] * (rewards[n] + gamma * v[nextState[0]][nextState[1]])\n",
        "                    temp.append(val_update)\n",
        "                v_updated[i][j] = max(temp)\n",
        "#                 print(v_updated)\n",
        "                optimal_policy[i][j] = temp.index(max(temp))\n",
        "        max_diff = max(max_diff, abs(v_updated[i][j] - v_s))\n",
        "    iteration_counter += 1\n",
        "    v = v_updated\n",
        "    if max_diff < delta:\n",
        "        break\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nNo of iterations: {} \\n\" .format(iteration_counter))\n",
        "print('*' * 50)\n",
        "print(\"\\nValue Function: \\n\")\n",
        "for i in range(gridRows):\n",
        "    for j in range(gridCols):\n",
        "        print(\"%.4f\" %v[i][j], \"  \", end='')\n",
        "    print(\"\\n\")\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nOptimal Policy: \\n\")\n",
        "for i in range(gridRows):\n",
        "    for j in range(gridCols):\n",
        "\n",
        "        if (i, j) in goal_states:\n",
        "            optimalAction = 'G'\n",
        "        elif (i, j) in obstacle_states:\n",
        "            optimalAction = ' '\n",
        "        else:\n",
        "            optimalAction = print_actions[int(optimal_policy[i][j])]\n",
        "\n",
        "        print(optimalAction, \"  \", end='')\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRFC4eGN4c5r",
        "outputId": "dbde40fe-6d2e-45ef-8889-0755d0c041d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "\n",
            "No of iterations: 16 \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Value Function: \n",
            "\n",
            "3.8464   4.3559   0.0000   5.7967   6.4533   \n",
            "\n",
            "4.3244   4.9893   5.7626   6.6453   7.3906   \n",
            "\n",
            "3.8203   4.3496   0.0000   7.5769   8.4637   \n",
            "\n",
            "3.3647   3.7892   0.0000   8.5738   9.6946   \n",
            "\n",
            "2.9247   2.8802   6.0733   9.6946   0.0000   \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Optimal Policy: \n",
            "\n",
            "→   ↓   G   ↓   ↓   \n",
            "\n",
            "→   →   →   ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑   →   →   G   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Answer 4a\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision = 4)\n",
        "gridRows, gridCols = 5, 5\n",
        "gamma = 0.9\n",
        "delta = 0.0001\n",
        "\n",
        "# Value Function\n",
        "v = np.zeros((gridRows, gridCols))\n",
        "\n",
        "# Rewards\n",
        "r = np.array([[0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, -10, 0, 10]])\n",
        "\n",
        "\n",
        "# State 1\n",
        "s0 = (0, 0)\n",
        "\n",
        "# Enviornment Dynamics: A Stochastic MDP\n",
        "water_state = (4, 2)\n",
        "goal_states = [(4, 4)]\n",
        "obstacle_states = [(2, 2), (3, 2)]\n",
        "actions = ['U', 'D', 'L', 'R']\n",
        "print_actions = [u\"\\u2191\", u\"\\u2193\", u\"\\u2190\", u\"\\u2192\"]\n",
        "\n",
        "r[0][2] = 4.999\n",
        "goal_states.append((0, 2))\n",
        "# Transition function\n",
        "def p(state, action):\n",
        "  next_states = []\n",
        "  next_state_prob = []\n",
        "  rewards = []\n",
        "\n",
        "  state_row, state_col = state[0], state[1]\n",
        "\n",
        "  if action == 'U':\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'D':\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "\n",
        "  if action == 'R':\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'L':\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  return next_states, next_state_prob, rewards\n",
        "\n",
        "# Value Iteration Algorithm\n",
        "iteration_counter = 0\n",
        "\n",
        "while True:\n",
        "    max_diff = 0\n",
        "    v_updated = np.zeros((gridRows, gridCols))\n",
        "    optimal_policy = np.zeros((gridRows, gridCols))\n",
        "    for i in range(gridRows):\n",
        "        for j in range(gridCols):\n",
        "            s = (i, j)\n",
        "            v_s = v[i][j]\n",
        "            if s in goal_states:\n",
        "                v_updated[i][j] = 0\n",
        "            elif s in obstacle_states:\n",
        "                v_updated[i][j] = 0\n",
        "            else:\n",
        "                temp = []\n",
        "                for a in actions:\n",
        "                    nextStates, next_state_prob, rewards = p(s, a)\n",
        "                    val_update = 0\n",
        "                    for n in range(len(nextStates)):\n",
        "                        nextState = nextStates[n]\n",
        "                        val_update += next_state_prob[n] * (rewards[n] + gamma * v[nextState[0]][nextState[1]])\n",
        "                    temp.append(val_update)\n",
        "                v_updated[i][j] = max(temp)\n",
        "#                 print(v_updated)\n",
        "                optimal_policy[i][j] = temp.index(max(temp))\n",
        "        max_diff = max(max_diff, abs(v_updated[i][j] - v_s))\n",
        "    iteration_counter += 1\n",
        "    v = v_updated\n",
        "    if max_diff < delta:\n",
        "        break\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nNo of iterations: {} \\n\" .format(iteration_counter))\n",
        "print('*' * 50)\n",
        "print(\"\\nValue Function: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "    print(\"%.4f\" %v[i][j], \"  \", end='')\n",
        "  print(\"\\n\")\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nOptimal Policy: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "\n",
        "    if (i, j) in goal_states:\n",
        "      optimalAction = 'G'\n",
        "    elif (i, j) in obstacle_states:\n",
        "      optimalAction = ' '\n",
        "    else:\n",
        "      optimalAction = print_actions[int(optimal_policy[i][j])]\n",
        "\n",
        "    print(optimalAction, \"  \", end='')\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuLQPUMj4c5r",
        "outputId": "3698f893-85a2-4459-aca9-0e8e81007093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "\n",
            "No of iterations: 16 \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Value Function: \n",
            "\n",
            "4.5197   4.9969   0.0000   6.3674   6.9930   \n",
            "\n",
            "5.0043   5.6279   6.3341   7.1649   7.8130   \n",
            "\n",
            "4.5213   5.0306   0.0000   7.9764   8.7259   \n",
            "\n",
            "4.0708   4.4916   0.0000   8.8201   9.7470   \n",
            "\n",
            "3.6163   3.5629   6.3182   9.7470   0.0000   \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Optimal Policy: \n",
            "\n",
            "↓   ↓   G   ↓   ↓   \n",
            "\n",
            "→   →   →   ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑   →   →   G   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Answer 4c\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision = 4)\n",
        "gridRows, gridCols = 5, 5\n",
        "gamma = 0.918\n",
        "delta = 0.0001\n",
        "\n",
        "# Value Function\n",
        "v = np.zeros((gridRows, gridCols))\n",
        "\n",
        "# Rewards\n",
        "r = np.array([[0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, -10, 0, 10]])\n",
        "\n",
        "\n",
        "# State 1\n",
        "s0 = (0, 0)\n",
        "\n",
        "# Enviornment Dynamics: A Stochastic MDP\n",
        "water_state = (4, 2)\n",
        "goal_states = [(4, 4)]\n",
        "obstacle_states = [(2, 2), (3, 2)]\n",
        "actions = ['U', 'D', 'L', 'R']\n",
        "print_actions = [u\"\\u2191\", u\"\\u2193\", u\"\\u2190\", u\"\\u2192\"]\n",
        "\n",
        "r[0][2] = 4.999\n",
        "goal_states.append((0, 2))\n",
        "# Transition function\n",
        "def p(state, action):\n",
        "  next_states = []\n",
        "  next_state_prob = []\n",
        "  rewards = []\n",
        "\n",
        "  state_row, state_col = state[0], state[1]\n",
        "\n",
        "  if action == 'U':\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'D':\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "\n",
        "  if action == 'R':\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'L':\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  return next_states, next_state_prob, rewards\n",
        "\n",
        "# Value Iteration Algorithm\n",
        "iteration_counter = 0\n",
        "\n",
        "while True:\n",
        "    max_diff = 0\n",
        "    v_updated = np.zeros((gridRows, gridCols))\n",
        "    optimal_policy = np.zeros((gridRows, gridCols))\n",
        "    for i in range(gridRows):\n",
        "        for j in range(gridCols):\n",
        "            s = (i, j)\n",
        "            v_s = v[i][j]\n",
        "            if s in goal_states:\n",
        "                v_updated[i][j] = 0\n",
        "            elif s in obstacle_states:\n",
        "                v_updated[i][j] = 0\n",
        "            else:\n",
        "                temp = []\n",
        "                for a in actions:\n",
        "                    nextStates, next_state_prob, rewards = p(s, a)\n",
        "                    val_update = 0\n",
        "                    for n in range(len(nextStates)):\n",
        "                        nextState = nextStates[n]\n",
        "                        val_update += next_state_prob[n] * (rewards[n] + gamma * v[nextState[0]][nextState[1]])\n",
        "                    temp.append(val_update)\n",
        "                v_updated[i][j] = max(temp)\n",
        "#                 print(v_updated)\n",
        "                optimal_policy[i][j] = temp.index(max(temp))\n",
        "        max_diff = max(max_diff, abs(v_updated[i][j] - v_s))\n",
        "    iteration_counter += 1\n",
        "    v = v_updated\n",
        "    if max_diff < delta:\n",
        "        break\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nNo of iterations: {} \\n\" .format(iteration_counter))\n",
        "print('*' * 50)\n",
        "print(\"\\nValue Function: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "    print(\"%.4f\" %v[i][j], \"  \", end='')\n",
        "  print(\"\\n\")\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nOptimal Policy: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "\n",
        "    if (i, j) in goal_states:\n",
        "      optimalAction = 'G'\n",
        "    elif (i, j) in obstacle_states:\n",
        "      optimalAction = ' '\n",
        "    else:\n",
        "      optimalAction = print_actions[int(optimal_policy[i][j])]\n",
        "\n",
        "    print(optimalAction, \"  \", end='')\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz_x4MnR4c5s",
        "outputId": "5b544f17-2fe4-443d-a805-dbd1b2476b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "\n",
            "No of iterations: 25 \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Value Function: \n",
            "\n",
            "3.8531   4.3586   0.0000   5.7968   6.4533   \n",
            "\n",
            "4.3282   4.9902   5.7626   6.6453   7.3906   \n",
            "\n",
            "3.8291   4.3529   0.0000   7.5769   8.4637   \n",
            "\n",
            "3.3849   3.7993   0.0000   8.5738   9.6946   \n",
            "\n",
            "2.9685   2.9037   6.0733   9.6946   0.0000   \n",
            "\n",
            "**************************************************\n",
            "\n",
            "Optimal Policy: \n",
            "\n",
            "→   ↓   G   ↓   ↓   \n",
            "\n",
            "→   →   →   ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑       ↓   ↓   \n",
            "\n",
            "↑   ↑   →   →   G   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Answer 5\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision = 4)\n",
        "gridRows, gridCols = 5, 5\n",
        "gamma = 0.9\n",
        "delta = 0.0001\n",
        "\n",
        "# Value Function\n",
        "v = np.zeros((gridRows, gridCols))\n",
        "\n",
        "# Rewards\n",
        "r = np.array([[0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, 0, 0, 0],\n",
        "              [0, 0, -10, 0, 10]])\n",
        "\n",
        "\n",
        "# State 1\n",
        "s0 = (0, 0)\n",
        "\n",
        "# Enviornment Dynamics: A Stochastic MDP\n",
        "water_state = (4, 2)\n",
        "goal_states = [(4, 4)]\n",
        "obstacle_states = [(2, 2), (3, 2)]\n",
        "actions = ['U', 'D', 'L', 'R']\n",
        "print_actions = [u\"\\u2191\", u\"\\u2193\", u\"\\u2190\", u\"\\u2192\"]\n",
        "\n",
        "r[0][2] = 4.999\n",
        "goal_states.append((0, 2))\n",
        "# Transition function\n",
        "def p(state, action):\n",
        "  next_states = []\n",
        "  next_state_prob = []\n",
        "  rewards = []\n",
        "\n",
        "  state_row, state_col = state[0], state[1]\n",
        "\n",
        "  if action == 'U':\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'D':\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row, state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "\n",
        "  if action == 'R':\n",
        "    if state_col == gridCols - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col + 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  if action == 'L':\n",
        "    if state_col == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row , state_col - 1)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.8)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == 0:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row - 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    if state_row == gridRows - 1:\n",
        "      nextState = state\n",
        "    else:\n",
        "      nextState = (state_row + 1, state_col)\n",
        "\n",
        "    if nextState in obstacle_states: # Obstacle\n",
        "      nextState = state\n",
        "\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.05)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "    nextState = state\n",
        "    next_states.append(nextState)\n",
        "    next_state_prob.append(0.1)\n",
        "    rewards.append(r[nextState[0], nextState[1]])\n",
        "\n",
        "  return next_states, next_state_prob, rewards\n",
        "\n",
        "# Value Iteration Algorithm\n",
        "iteration_counter = 0\n",
        "\n",
        "while True:\n",
        "  diff = 0\n",
        "  v_updated = np.zeros((gridRows, gridCols))\n",
        "  optimal_policy = np.zeros((gridRows, gridCols))\n",
        "\n",
        "  for i in range(gridRows):\n",
        "    for j in range(gridCols):\n",
        "\n",
        "      s = (i, j)\n",
        "      v_s = v[i][j]\n",
        "\n",
        "      if s in goal_states:\n",
        "        v_updated[i][j] = 0\n",
        "      elif s in obstacle_states:\n",
        "        v_updated[i][j] = 0\n",
        "      else:\n",
        "        temp = []\n",
        "        for a in actions:\n",
        "          nextStates, next_state_prob, rewards = p(s, a)\n",
        "          val_update = 0\n",
        "          n=0\n",
        "          while n<len(nextStates):\n",
        "            nextState = nextStates[n]\n",
        "            val_update += next_state_prob[n] * (rewards[n] + gamma * v[nextState[0]][nextState[1]])\n",
        "            n+=1\n",
        "          temp.append(val_update)\n",
        "        v_updated[i][j] = max(temp)\n",
        "        optimal_policy[i][j] = temp.index(max(temp))\n",
        "#         print(v_updated)\n",
        "      diff = max(diff, abs(v_updated[i][j] - v_s))\n",
        "\n",
        "  iteration_counter += 1\n",
        "  v = v_updated\n",
        "  if diff < delta:\n",
        "    break\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nNo of iterations: {} \\n\" .format(iteration_counter))\n",
        "print('*' * 50)\n",
        "print(\"\\nValue Function: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "    print(\"%.4f\" %v[i][j], \"  \", end='')\n",
        "  print(\"\\n\")\n",
        "\n",
        "print('*' * 50)\n",
        "print(\"\\nOptimal Policy: \\n\")\n",
        "for i in range(gridRows):\n",
        "  for j in range(gridCols):\n",
        "\n",
        "    if (i, j) in goal_states:\n",
        "      optimalAction = 'G'\n",
        "    elif (i, j) in obstacle_states:\n",
        "      optimalAction = ' '\n",
        "    else:\n",
        "      optimalAction = print_actions[int(optimal_policy[i][j])]\n",
        "\n",
        "    print(optimalAction, \"  \", end='')\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjom-Jyk4c5s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}